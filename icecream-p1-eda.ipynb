{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loading Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading dataset\n",
    "\n",
    "df = pd.read_csv(\"products.csv\")\n",
    "print(\"the dataset has \" + str(df.shape[0]) + \" observations (ice cream flavors) and \" + str(df.shape[1]) + \" features \" + str([col for col in df.columns]))\n",
    "\n",
    "# dataset: https://www.kaggle.com/datasets/tysonpo/ice-cream-dataset\n",
    "\n",
    "# Inspiration Notebooks:\n",
    "# Using Ice Cream Ingredients to Predict Rating: https://www.kaggle.com/code/gcdatkin/using-ice-cream-ingredients-to-predict-rating\n",
    "# Finding the Best Ice Cream: https://www.kaggle.com/code/kelvintran1998/finding-the-best-ice-cream\n",
    "# EDA ideas: McDonalds Ice Cream Machines Breaking: https://www.kaggle.com/code/aashidutt3/eda-mcdonalds-ice-cream-machines-breaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data Cleaning: transform brand feature to more readable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change brand name to be more readable\n",
    "\n",
    "df['brand'] = df['brand'].replace(['hd','breyers','bj','talenti'],['HaagenDazs','Breyers','BenJerrys','Talenti'])\n",
    "df['brand'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Exploratory Data Analysis: Color Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataviz libraries\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color scheme\n",
    "\n",
    "class clr:\n",
    "    S = '\\033[1m' + '\\033[96m' # chance color text\n",
    "    E = '\\033[0m'\n",
    "    \n",
    "my_colors = ['#1F6082', '#6A2340', '#83563f', '#495057']\n",
    "\n",
    "sns.palplot(sns.color_palette(my_colors))\n",
    "\n",
    "print(clr.S + \"Notebook Color Scheme: \" + clr.E)\n",
    "print(r\"Ben Jerry's, HÃ¤agen-Dazs, Talenti, Breyers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create color reference dict\n",
    "# the idea is to use this dict to sort the color code in the same way of the plot\n",
    "# colors = ['#1F6082', '#6A2340', '#83563f', '#171717']\n",
    "\n",
    "color_reference = {'BenJerrys':'#1F6082', 'Breyers':'#495057', 'HaagenDazs':'#6A2340', 'Talenti':'#83563f'}\n",
    "color_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting and standardizing parameters for all graphs\n",
    "\n",
    "sns.set()\n",
    "plt.style.use('seaborn-v0_8-notebook')\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 12,8\n",
    "rcParams['figure.titlesize'] = 14\n",
    "rcParams['font.size'] = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change column names\n",
    "\n",
    "flavors = df['brand'].value_counts().reset_index().sort_values('brand', ascending=False)\n",
    "flavors = flavors.rename(columns = {'index':'brand', 'brand':'value_counts'})\n",
    "flavors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the brands flavors counts\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "colors = flavors['brand'].replace(color_reference) # replace elements in a list using dictionary lookup\n",
    "colors = colors.tolist() # list of colors for palette parameter in sns plot\n",
    "splot = sns.barplot(data=flavors, x='brand', y='value_counts', palette=colors)\n",
    "plt.ylim([0,80])\n",
    "for p in splot.patches:\n",
    "    splot.annotate(format(p.get_height(), '.0f'), \n",
    "                   (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                   ha = 'center', va = 'center', \n",
    "                   xytext = (0, 9), \n",
    "                   textcoords = 'offset points')\n",
    "plt.xlabel('Brand', fontsize=14)\n",
    "plt.ylabel('# Flavors', fontsize=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Exploratory Data Analysis: Flavors vs Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating distribution\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(data=df, x='rating', hue='brand', multiple='stack', palette=color_reference)\n",
    "plt.xlim([0,5.0])\n",
    "plt.xticks(np.arange(0,5.1, step=0.5))\n",
    "plt.xlabel('Average Rating', fontsize=14)\n",
    "plt.ylabel('Flavors', fontsize=14)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating kurtosis and Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy\n",
    "from scipy.stats import skew, kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the skewness\n",
    "\n",
    "skewness = skew(df['rating'], axis=0)\n",
    "\n",
    "if skewness == 0:\n",
    "    print('the skewness value is ' + str(round(skewness,2)) + '. Then normally distributed.')\n",
    "if skewness > 0:\n",
    "    print('the skewness value is ' + str(round(skewness,2)) + '. Then more weight in the left tail of the distribution.')\n",
    "if skewness < 0:\n",
    "    print('the skewness value is ' + str(round(skewness,2)) + '. Then more weight in the right tail of the distribution.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the kurtosis\n",
    "kurt =  kurtosis(df['rating'], axis=0)\n",
    "\n",
    "if kurt == 3:\n",
    "    print('the skewness value is ' + str(round(kurt,2)) + '. Then the distribution is mesokurtic.')\n",
    "if kurt < 3:\n",
    "    print('the skewness value is ' + str(round(kurt,2)) + '. Then the distribution is platykurtic (short tails).')\n",
    "if kurt > 3:\n",
    "    print('the skewness value is ' + str(round(kurt,2)) + '. Then the distribution is leptokurtic (thinner in the center and fatter tails. ie more outliers)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change column names\n",
    "\n",
    "ratings_by_brand = df.groupby('brand')['rating_count'].sum().reset_index().sort_values('brand', ascending=True)\n",
    "ratings_by_brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the brands flavors counts\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "colors = ratings_by_brand['brand'].replace(color_reference) # replace elements in a list using dictionary lookup\n",
    "colors = colors.tolist() # list of colors for palette parameter in sns plot\n",
    "splot = sns.barplot(data=ratings_by_brand, x='brand', y='rating_count', palette=colors)\n",
    "plt.ylim([0,9000])\n",
    "for p in splot.patches:\n",
    "    splot.annotate(format(p.get_height(), '.0f'), \n",
    "                   (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                   ha = 'center', va = 'center', \n",
    "                   xytext = (0, 9), \n",
    "                   textcoords = 'offset points')\n",
    "plt.xlabel('Brand', size=14)\n",
    "plt.ylabel('# Reviews', size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot by brand\n",
    "\n",
    "sns.relplot(data=df,\n",
    "                x='rating', y='rating_count',\n",
    "                hue='brand',\n",
    "                col='brand',\n",
    "                palette=my_colors,\n",
    "                sizes=(1, 6), linewidth=0, col_wrap=2\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot by rating vs. brand\n",
    "\n",
    "_, axs = plt.subplots(nrows=1, ncols=2) # making a subplot with 1 row and 2 columns\n",
    "sns.stripplot(data=df, x='brand', y='rating', palette=my_colors, ax=axs[0])\n",
    "sns.boxplot(data=df, x='brand', y='rating', palette=my_colors, ax=axs[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Flavors with low rating counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_rating_count = df.query('rating_count < 10') # number choosed arbritrary\n",
    "low_rating_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Worst Ice Creams and checking their reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst10 = df.sort_values('rating').head(10)\n",
    "worst10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the ice cream reviews dataset\n",
    "\n",
    "df_reviews = pd.read_csv(\"reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of values to filter by ice cream's keys\n",
    "\n",
    "values_list = worst10['key'].unique()\n",
    "\n",
    "# filtering by two conditions: ice creams worst ratings and one star reviews\n",
    "filtered_reviews = df_reviews[df_reviews['key'].isin(values_list)]\n",
    "worst10_1star_reviews =  filtered_reviews.query('stars == 1') # getting one starred reviews for the \n",
    "\n",
    "# cleaning the worst10_1star_reviews df to become more readable\n",
    "worst10_1star_reviews['brand'] = worst10_1star_reviews['brand'].replace(['hd','breyers','bj','talenti'],['HaagenDazs','Breyers','BenJerrys','Talenti'])\n",
    "worst10_1star_reviews = worst10_1star_reviews.drop(columns=['key','author', 'date', 'taste', 'ingredients', 'texture', 'likes', 'helpful_yes', 'helpful_no'])\n",
    "worst10_1star_reviews"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data Cleaning: dropping unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this work, we don't need to use these columns, so we will drop it\n",
    "\n",
    "df = df.drop(columns=['key','subhead','description'])\n",
    "worst10 = worst10.drop(columns=['key','subhead','ingredients'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Top Ice Cream for each brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 Ben & Jerry's ice creams\n",
    "\n",
    "top10_bj = df[df['brand'] == 'BenJerrys'].sort_values(by=['rating','rating_count'], ascending=False).head(10)\n",
    "top10_bj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 Haagen Dazs ice creams\n",
    "\n",
    "top10_hd = df[df['brand'] == 'HaagenDazs'].sort_values(by=['rating','rating_count'], ascending=False).head(10)\n",
    "top10_hd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 Talenti ice creams\n",
    "\n",
    "top10_tl = df[df['brand'] == 'Talenti'].sort_values(by=['rating','rating_count'], ascending=False).head(10)\n",
    "top10_tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 Breyers ice creams\n",
    "\n",
    "top10_br = df[df['brand'] == 'Breyers'].sort_values(by=['rating','rating_count'], ascending=False).head(10)\n",
    "top10_br"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bottom Ice Cream for each brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom 10 Ben & Jerry's ice creams\n",
    "\n",
    "bot10_bj = df[df['brand'] == 'BenJerrys'].sort_values(by=['rating','rating_count'], ascending=False).tail(10)\n",
    "bot10_bj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom 10 Haagen Dazs ice creams\n",
    "\n",
    "bot10_hd = df[df['brand'] == 'HaagenDazs'].sort_values(by=['rating','rating_count'], ascending=False).tail(10)\n",
    "bot10_hd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom 10 Talenti ice creams\n",
    "\n",
    "bot10_tl = df[df['brand'] == 'Talenti'].sort_values(by=['rating','rating_count'], ascending=False).tail(10)\n",
    "bot10_tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom 10 Breyers ice creams\n",
    "\n",
    "bot10_br = df[df['brand'] == 'Breyers'].sort_values(by=['rating','rating_count'], ascending=False).tail(10)\n",
    "bot10_br"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Top10 and Bot10 Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a table to compare the average score with the average top10 score for each brand\n",
    "\n",
    "grouped = df.groupby('brand')['rating'].mean().round(2)\n",
    "new_column_rating_count = df.groupby('brand')['rating_count'].sum()\n",
    "grouped = pd.concat([grouped, new_column_rating_count], axis=1).rename(columns={'rating':'rating_avg'})\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating and inserting the top10 values to the table:\n",
    "top10grouped = grouped.copy()\n",
    "brand_dict = {'BenJerrys': top10_bj, 'Breyers': top10_br, 'HaagenDazs': top10_hd, 'Talenti': top10_tl}\n",
    "\n",
    "for brand, top10_df in brand_dict.items():\n",
    "    grouped_mean = top10_df.groupby('brand')['rating'].mean()\n",
    "    \n",
    "    grouped_count = top10_df.groupby('brand')['rating_count'].sum()\n",
    "    grouped_top10 = pd.concat([grouped_mean, grouped_count], axis=1)\n",
    "    grouped_top10 = grouped_top10.rename(columns={'rating': 'top10_rating_avg', 'rating_count':'top10_count'})\n",
    "\n",
    "    # inserting these values into the table generated on the previous step:\n",
    "    top10grouped.loc[brand, 'top10_rating_avg'] = grouped_top10['top10_rating_avg'][0]\n",
    "    top10grouped.loc[brand, 'top10_count'] = grouped_top10['top10_count'][0]\n",
    "\n",
    "top10grouped['top10_count'] = top10grouped['top10_count'].astype(int)\n",
    "top10grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bottom10 Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating and inserting the bot10 values to the table:\n",
    "bot10grouped = grouped.copy()\n",
    "brand_dict = {'BenJerrys': bot10_bj, 'Breyers': bot10_br, 'HaagenDazs': bot10_hd, 'Talenti': bot10_tl}\n",
    "\n",
    "for brand, bot10_df in brand_dict.items():\n",
    "    grouped_mean = bot10_df.groupby('brand')['rating'].mean()\n",
    "    \n",
    "    grouped_count = bot10_df.groupby('brand')['rating_count'].sum()\n",
    "    grouped_bot10 = pd.concat([grouped_mean, grouped_count], axis=1)\n",
    "    grouped_bot10 = grouped_bot10.rename(columns={'rating': 'bot10_rating_avg', 'rating_count':'bot10_count'})\n",
    "\n",
    "    # inserting these values into the table generated on the previous step:\n",
    "    bot10grouped.loc[brand, 'bot10_rating_avg'] = grouped_bot10['bot10_rating_avg'][0]\n",
    "    bot10grouped.loc[brand, 'bot10_count'] = grouped_bot10['bot10_count'][0]\n",
    "\n",
    "bot10grouped['bot10_count'] = bot10grouped['bot10_count'].astype(int)\n",
    "bot10grouped"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Results in csv Files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creating gist csv files for the medium articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head().to_csv('icecream_head.csv', index=False, header=True, encoding='cp1252')\n",
    "#df.tail().to_csv('icecream_tail.csv', index=False, header=True, encoding='cp1252')\n",
    "#low_rating_count.to_csv('icecream_low_rating_count.csv', index=False, header=True, encoding='cp1252')\n",
    "#worst10.to_csv('icecream_worst_flavors.csv', index=False, header=True, encoding='cp1252')\n",
    "#worst10_1star_reviews.to_csv('icecream_worst10_1star_reviews.csv', index=False, header=True, encoding='cp1252')\n",
    "#negative_reviews.to_csv('icecream_worst10_negative_reviews.csv', index=False, header=True, encoding='utf-8')\n",
    "#top10grouped.to_csv('icecream_top10bot10grouped.csv', index=True, header=True, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating the top and bottom tables to generate csv gists\n",
    "\n",
    "#top_bot_list = {'top10_bj':top10_bj, 'top10_hd':top10_hd, 'top10_tl':top10_tl, 'top10_br':top10_br, 'bot10_bj':bot10_bj, 'bot10_hd':bot10_hd, 'bot10_tl':bot10_tl, 'bot10_br':bot10_br}\n",
    "\n",
    "#for top_bot_csvname, top_bot_df  in top_bot_list.items():\n",
    "    #csv_name = 'icecream_' + top_bot_csvname + '.csv'\n",
    "    #top_bot_df.to_csv(csv_name, index=False, header=True, encoding='cp1252')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Saving the pre-processing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use this csv file in the next project phase\n",
    "\n",
    "df.to_csv('pre-processed.csv', index=False, header=True, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f5c964f10db18ca2e24ede473c8e1bbf38968f9e6b980b72f721a488ad58e77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
